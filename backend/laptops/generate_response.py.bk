"""
Laptops Neural Search.

This module contains functionalities that handle cleaning, classifying
and embedding of laptop data. It also realease an Object wich can be used
to interact with the neural search engine.
"""

import cohere
import os
import threading
from config import DATABASE
from cohere.classify import Example
import json


NUM_OF_THREADS = 10
LAPTOP_DATABASE = DATABASE.joinpath("laptops_raw.json")

client = cohere.Client(os.environ["COHERE_API_KEY"])


def generate_description(data) -> str:
    """
    Generate description for laptop.

    Args:
        data: the data to use to generate the description
    """
    prompt = (
        "This is an informative persuasive pitch "
        "for a salesperson trying to sell a laptop to a customer."
        "focus on the features of the laptop that is"
        "The information of the laptop in json format is {data}."
        "The sales person to  the customer:"
    ).format(data=data)
    response = client.generate(
        model="command-xlarge-nightly",
        prompt=prompt, max_tokens=400,
        temperature=1.5, k=2
    )
    return response.generations[0].text


def classify_based_on_group() -> None:
    """
    Classify laptops based on users.

    Laptops can be further classified based on the group
    of users that the laptop was aimed at, these groups are:

    - Everyday users
    - Students
    - Business professionals
    - Creative professionals
    - Gamers
    - Hardcore users
    """
    examples = [
        Example("Intel Core i7 - i7-11800H - 8 cores - 17.3 inch - 16GB - 512GB SSD - Black - 9S7-17L212-655", "Hardcore users"),
        Example("Intel Core i7 - i7-12700H - 14 cores - 15.6 inch - 16GB - 1000GB SSD - Gray, Titanium - GL6612UEK021NL", "Hardcore users"),
        Example("2021 - Apple M1 Pro - Apple M1 Pro - 8 cores - 14.2 inch - 16GB - 512GB SSD - Silver - MKGR3LL/A", "Creative professionals"),
        Example("Intel Core i9 - i9-12900H - 14 cores - 16 inch - 32GB - 2000GB SSD - Gray - CREATOR Z16P B12UGST-019BE", "Creative professionals"),
        Example("Intel Core i5 - i5-1235U - 10 cores - 15.6 inch - 8GB - 512GB SSD - Metallic - 30034235", "Everyday users"),
        Example("AMD Ryzen 5 - 4680U - 4 cores - 13.5 inch - 16GB - 256GB SSD - Matte Black - 7IQ-00032", "Everyday users"),
        Example("2020 - Intel 10th Generation Core i7 - 1065G7 - 4 cores - 15 inch - 32GB - 512GB SSD - Platinum - SMN-00001", "Business professionals"),
        Example("2022 - Intel Core i7 - i7-1255U - 10 cores - 16 inch - 16GB - 512GB - 512GB SSD - SILVER | BLACK - 5P6R7EA#ABB", "Business professionals"),
        Example("AMD Ryzen 9 - 6900HS - 8 cores - 14 inch - 16GB - 1000GB SSD - Eclipse Gray AniMe Matrix version - 90NR09T4-M00430", "Gamers"),
        Example("AMD Ryzen 9 - 5900HX - 8 cores - 16 inch - 32GB - 2000GB SSD - Gray - 82N600MWMB", "Gamers"),
        Example("AMD Ryzen 5 - 5500U - 6 cores - 15.6 inch - 8GB - 256GB - 256GB SSD - Black - 82KD002RIX", "Students"),
        Example("Intel Core i5 - 1235U - 10 cores - 17.3 inch - 32GB - 1000GB SSD - Silver - 24619", "Students"),
    ]
    inputs = []
    classifications: list[list[str]] = []
    print("fetching data...")
    with open(DATABASE.joinpath("laptops_raw.json")) as db:
        count = 0
        for laptop in json.load(db):
            if count >= 20:
                break
            inputs.append(laptop["info"])
            count += 1
    print(f"input length: {len(inputs)}")
    print("classifying data...")
    response = client.classify(inputs=inputs, examples=examples, model="large")
    print("computing predictions...")
    for classification in response.classifications:
        labels = []
        predictions: list[tuple[str, float]] = []
        for label, pred in classification.labels.items():
            predictions.append((label, pred.confidence))
        predictions.sort(key=lambda p: p[1])
        for pred in predictions:
            if pred[1] > 5:
                labels.append(pred[0])
        if not labels:
            labels.append(classification.prediction)
        classifications.append(labels)
    print("saving...")
    with open(DATABASE.joinpath("laptops_by_user.json"), "w+") as f:
        json.dump(classifications, f, indent=1)



def interpret(phone):
    """
    The interpret function takes a dictionary and then calls on cohere AI
    the cohere Ai now interprets this dictionary in a user friendly for
    """
    info = str(phone)
    prompt = f"This is an informative, persuasive salesman marketing for an gadgets company trying to sell a\
    product, the information for the gatget in json format is {info}, the salesman tells our customer:"
    co = cohere.Client(os.getenv("COHERE_API_KEY"))
    response = co.generate(  
        model='command-xlarge-nightly',  
        prompt = prompt,  
        max_tokens=400,
        temperature=1.5,
        k=2)
    res = response.generations[0].text
    print(res)
    return res;


def classify_based_on_group(data: list[dict], status=None) -> list[list[str]]:
    """
    Classify laptops based on users.

    Laptops can be further classified based on the group
    of users that the laptop was aimed at, these groups are:

    - Everyday users
    - Students
    - Business professionals
    - Creative professionals
    - Gamers
    - Hardcore users

    Args:
        data: A list of dictionaries, each representing a laptop
    Returns:
        a list of classifications for each laptop
    """
    
    examples: list[Example] = []
    classifications: list[list[str]] = []

    def classify(batch: list[str]):
        # Classify the inputs using the Cohere API
        response = client.classify(inputs=batch, examples=examples, model="large")
    
        status.update("Processing classifications...")
        # Extract the classification labels and confidences for each input
        for classification in response.classifications:
            labels = []
            predictions: list[tuple[str, float]] = []
            for label, pred in classification.labels.items():
                # Append the (label, confidence) tuple to the predictions list
                predictions.append((label, pred.confidence))
            # Sort the predictions list in ascending order of confidence
            predictions.sort(key=lambda p: p[1])
            # Only keep the labels with a confidence greater than 5
            for pred in predictions:
                if pred[1] > 5:
                    labels.append(pred[0])
            # If no labels meet the confidence threshold, use the predicted label
            if not labels:
                labels.append(classification.prediction)
            # Append the labels to the classifications list
            classifications.append(labels)

    # Load the examples from a json file located in the same directory as this script
    examples_file = Path(__file__).parent.joinpath("users_examples.json")
    for ex in json.loads(examples_file.read_text()):
        # Create an Example object from each example in the file and append it to the examples list
        examples.append(Example(ex[0], ex[1]))
    
    status.update("Fetching data...")
    # Extract the input texts from the input dictionaries
    batch: list[str] = []
    batch_count = 1
    for laptop in data:
        if len(batch) >= 96:
            status.update(f"Classifying batch {batch_count}...")
            classify(batch)
            batch = []
            batch_count += 1
        batch.append(laptop["info"] or laptop["name"])
    if len(batch) >= 1:
        status.update(f"Classifying batch {batch_count}...")
        classify(batch)
        batch = []
        batch_count += 1
        
    
    return classifications

